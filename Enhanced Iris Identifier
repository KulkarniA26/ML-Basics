ML Process -load data -pre processing -training a model -evaluating a
model -making predictions


+*In[3]:*+
[source, ipython3]
----
#import necessary librarues
import pandas as pd
from sklearn.linear_model import LogisticRegression
import numpy as np
from sklearn.model_selection import train_test_split 
#split data in training and testing sets.
from sklearn.preprocessing import StandardScaler 
#standardize features, mean 0, sd 1 - to make all features and variables are on same scale avoid unbalanced weightage
from sklearn.metrics import accuracy_score 
#calculate model prediction accuracy - validation - seperate dataset - doesnt overfit training data.
----


+*In[4]:*+
[source, ipython3]
----
iris_data = pd.read_csv('iris.csv')
iris_data.head()
----


+*Out[4]:*+
----
[cols=",,,,,",options="header",]
|===
| |sepal.length |sepal.width |petal.length |petal.width |variety
|0 |5.1 |3.5 |1.4 |0.2 |Setosa
|1 |4.9 |3.0 |1.4 |0.2 |Setosa
|2 |4.7 |3.2 |1.3 |0.2 |Setosa
|3 |4.6 |3.1 |1.5 |0.2 |Setosa
|4 |5.0 |3.6 |1.4 |0.2 |Setosa
|===
----


+*In[5]:*+
[source, ipython3]
----
#split data inst features as (x) and labels (y)
x = iris_data.drop(columns = ['variety'])
y = iris_data['variety']
----


+*In[6]:*+
[source, ipython3]
----
X_train,x_test,Y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 42)
#training data for x, test data for x,
#training data for y, test data for y,
#random_state helps to repeat the same data, or can be used in future to recall the test and training data sets - can be used to compare results
----


+*In[7]:*+
[source, ipython3]
----
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train) # standardize the features
x_test_scaled = scaler.transform(x_test) 
#standardizing the features
----


+*In[8]:*+
[source, ipython3]
----
#create a ML Model - initalizes model using default settings
model = LogisticRegression(max_iter=500, solver='lbfgs')
----


+*In[9]:*+
[source, ipython3]
----
#train the model - fit method - trains logisticregression - of values x for corresponding y labels
#learning relation between features(input) and target (output) variables
----


+*In[12]:*+
[source, ipython3]
----
model.fit(X_train_scaled, Y_train) 
#instead of using values from data, use set of training values, training the model.
----


+*Out[12]:*+
----
[[sk-container-id-2]]
....
LogisticRegression(max_iter=500)
....

*In a Jupyter environment, please rerun this cell to show the HTML
representation or trust the notebook. +
On GitHub, the HTML representation is unable to render, please try
loading this page with nbviewer.org.*

LogisticRegression

https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html[?Documentation
for LogisticRegression][.sk-estimator-doc-link .fitted]##iFitted##

....
LogisticRegression(max_iter=500)
....
----


+*In[ ]:*+
[source, ipython3]
----
#will predict using the above model for the given input values - 2darray - evaluate model on testing set
----


+*In[15]:*+
[source, ipython3]
----
y_pred = model.predict(x_test_scaled)
accuracy = accuracy_score(y_test,y_pred)
print("Accuracy: ", accuracy) #higher the accuracy score the better model
----


+*Out[15]:*+
----
Accuracy:  1.0
----


+*In[16]:*+
[source, ipython3]
----
y_pred #predicted labels
----


+*Out[16]:*+
----array(['Versicolor', 'Setosa', 'Virginica', 'Versicolor', 'Versicolor',
       'Setosa', 'Versicolor', 'Virginica', 'Versicolor', 'Versicolor',
       'Virginica', 'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Versicolor',
       'Virginica', 'Versicolor', 'Versicolor', 'Virginica', 'Setosa',
       'Virginica', 'Setosa', 'Virginica', 'Virginica', 'Virginica',
       'Virginica', 'Virginica', 'Setosa', 'Setosa'], dtype=object)----


+*In[22]:*+
[source, ipython3]
----
new_data = np.random.uniform(low=0.2, high=7, size=(3, 4))
new_data = np.round(new_data, decimals=1)
new_data 
#this data is newly generated and not seen by the model, we will use it to test the model.
----


+*Out[22]:*+
----array([[5.9, 2.7, 3.2, 6.4],
       [1.2, 4.7, 4.9, 3.8],
       [3. , 4.9, 2.6, 2.3]])----


+*In[24]:*+
[source, ipython3]
----
#standardizing the new data 
new_data_scaled = scaler.transform(new_data)
----


+*Out[24]:*+
----
C:\Aditya\aditya\sql-ultimate-course\ad3\Lib\site-packages\sklearn\utils\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names
  warnings.warn(
----


+*In[25]:*+
[source, ipython3]
----
#prediction of new data
prediction = model.predict(new_data_scaled)
----


+*In[26]:*+
[source, ipython3]
----
prediction
----


+*Out[26]:*+
----array(['Virginica', 'Setosa', 'Setosa'], dtype=object)----


+*In[ ]:*+
[source, ipython3]
----

----
